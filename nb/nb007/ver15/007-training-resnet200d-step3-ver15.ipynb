{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# Directory settings\n",
    "# =======================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "TRAIN_PATH = '/home/yuki/RANZCR/input/ranzcr-clip-catheter-line-classification/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/yuki/RANZCR/input/ranzcr-clip-catheter-line-classification/train.csv')\n",
    "test = pd.read_csv('/home/yuki/RANZCR/input/ranzcr-clip-catheter-line-classification/sample_submission.csv')\n",
    "train_annotations = pd.read_csv('/home/yuki/RANZCR/input/ranzcr-clip-catheter-line-classification/train_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    device='GPU' # ['TPU', 'GPU']\n",
    "    nprocs=1 # [1, 8]\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name='resnet200d_320'\n",
    "    size=640\n",
    "    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    teacher='/home/yuki/RANZCR/input/005-training-resnext-step1-data/resnet200d_320_fold0_best_loss_cpu.pth'\n",
    "    student='/home/yuki/RANZCR/input/006-training-resnext-step2-data/resnet200d_320_fold0_epoch5.pth'\n",
    "    epochs=5\n",
    "    #factor=0.2 # ReduceLROnPlateau\n",
    "    #patience=4 # ReduceLROnPlateau\n",
    "    #eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=5 # CosineAnnealingLR\n",
    "    T_0=5 # CosineAnnealingWarmRestarts\n",
    "    alpha=1 # FocalLoss \n",
    "    gamma=0.1 # FocalLoss\n",
    "    lr=2e-5 # 1e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=16 # 64\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=416\n",
    "    target_size=11\n",
    "    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                 'Swan Ganz Catheter Present']\n",
    "    n_fold=5\n",
    "    trn_fold=[0] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 3\n",
    "    train = train.sample(n=3000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.device == 'TPU':\n",
    "    import os\n",
    "    os.system('curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py')\n",
    "    os.system('python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev')\n",
    "    os.system('export XLA_USE_BF16=1')\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "    CFG.lr = CFG.lr * CFG.nprocs\n",
    "    CFG.batch_size = CFG.batch_size // CFG.nprocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('/home/yuki/RANZCR/input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import timm\n",
    "\n",
    "if CFG.device == 'TPU':\n",
    "    import ignite.distributed as idist\n",
    "elif CFG.device == 'GPU':\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        score = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "        scores.append(score)\n",
    "    avg_score = np.mean(scores)\n",
    "    return avg_score, scores\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f}')\n",
    "    \n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    6017\n",
       "1    6017\n",
       "2    6017\n",
       "3    6016\n",
       "4    6016\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = folds['PatientID'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_cols], groups)):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "COLOR_MAP = {'ETT - Abnormal': (255, 0, 0),\n",
    "             'ETT - Borderline': (0, 255, 0),\n",
    "             'ETT - Normal': (0, 0, 255),\n",
    "             'NGT - Abnormal': (255, 255, 0),\n",
    "             'NGT - Borderline': (255, 0, 255),\n",
    "             'NGT - Incompletely Imaged': (0, 255, 255),\n",
    "             'NGT - Normal': (128, 0, 0),\n",
    "             'CVC - Abnormal': (0, 128, 0),\n",
    "             'CVC - Borderline': (0, 0, 128),\n",
    "             'CVC - Normal': (128, 128, 0),\n",
    "             'Swan Ganz Catheter Present': (128, 0, 128),\n",
    "            }\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['StudyInstanceUID'].values\n",
    "        self.labels = df[CFG.target_cols].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        file_path = f'{TRAIN_PATH}/{file_name}.jpg'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            CoarseDropout(p=0.2),\n",
    "            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# MODEL\n",
    "# ====================================================\n",
    "class CustomResNet200D(nn.Module):\n",
    "    def __init__(self, model_name='resnet200d_320', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False)\n",
    "        if pretrained:\n",
    "            pretrained_path = '../input/resnet200d-pretrained-weight/resnet200d_ra2-bdba9bf9.pth'\n",
    "            self.model.load_state_dict(torch.load(pretrained_path))\n",
    "            print(f'load {model_name} pretrained model')\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, CFG.target_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return features, pooled_features, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, preds, targets):\n",
    "        loss_fct = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        bce_loss = loss_fct(preds, targets)\n",
    "        preds_sigmoid = torch.sigmoid(preds)\n",
    "        loss = torch.where(targets >= 0.5, self.alpha * (1. - preds_sigmoid) ** self.gamma * bce_loss, preds_sigmoid ** self.gamma * bce_loss)\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def train_fn(train_loader, model, train_fc, valid_fc, optimizer, epoch, scheduler, device):\n",
    "    if CFG.device == 'GPU':\n",
    "        scaler = GradScaler()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if CFG.device == 'GPU':\n",
    "            with autocast():\n",
    "                _, _, y_preds = model(images)\n",
    "                loss = train_fc(y_preds, labels)\n",
    "                metric = valid_fc(y_preds, labels)\n",
    "                # record loss\n",
    "                losses.update(metric.item(), batch_size)\n",
    "                if CFG.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / CFG.gradient_accumulation_steps\n",
    "                scaler.scale(loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "                    \n",
    "        elif CFG.device == 'TPU':\n",
    "            _, _, y_preds = model(images)\n",
    "            loss = train_fc(y_preds, labels)\n",
    "            metric = valid_fc(y_preds, labels)\n",
    "            # record loss\n",
    "            losses.update(metric.item(), batch_size)\n",
    "            if CFG.gradient_accumulation_steps > 1:\n",
    "                loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "                xm.optimizer_step(optimizer, barrier=True)\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      #'LR: {lr:.6f}  '\n",
    "                      .format(\n",
    "                       epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                       grad_norm=grad_norm,\n",
    "                       #lr=scheduler.get_lr()[0],\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "                xm.master_print('Epoch: [{0}][{1}/{2}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                'Grad: {grad_norm:.4f}  '\n",
    "                                #'LR: {lr:.6f}  '\n",
    "                                .format(\n",
    "                                epoch+1, step, len(train_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                                grad_norm=grad_norm,\n",
    "                                #lr=scheduler.get_lr()[0],\n",
    "                                ))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, valid_fc, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    trues = []\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            _, _, y_preds = model(images)\n",
    "        loss = valid_fc(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        trues.append(labels.to('cpu').numpy())\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if CFG.device == 'GPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                      .format(\n",
    "                       step, len(valid_loader), batch_time=batch_time,\n",
    "                       data_time=data_time, loss=losses,\n",
    "                       remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                       ))\n",
    "        elif CFG.device == 'TPU':\n",
    "            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "                xm.master_print('EVAL: [{0}/{1}] '\n",
    "                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                                'Elapsed {remain:s} '\n",
    "                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                                .format(\n",
    "                                step, len(valid_loader), batch_time=batch_time,\n",
    "                                data_time=data_time, loss=losses,\n",
    "                                remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                                ))\n",
    "    trues = np.concatenate(trues)\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions, trues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "\n",
    "    if CFG.device == 'GPU':\n",
    "        LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "    elif CFG.device == 'TPU':\n",
    "        if CFG.nprocs == 1:\n",
    "            LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "        elif CFG.nprocs == 8:\n",
    "            xm.master_print(f\"========== fold: {fold} training ==========\")\n",
    "            \n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_cols].values\n",
    "\n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "    \n",
    "    if CFG.device == 'GPU':\n",
    "        train_loader = DataLoader(train_dataset, \n",
    "                                  batch_size=CFG.batch_size, \n",
    "                                  shuffle=True, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "        valid_loader = DataLoader(valid_dataset, \n",
    "                                  batch_size=CFG.batch_size * 2, \n",
    "                                  shuffle=False, \n",
    "                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "        \n",
    "    elif CFG.device == 'TPU':\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                        num_replicas=xm.xrt_world_size(),\n",
    "                                                                        rank=xm.get_ordinal(),\n",
    "                                                                        shuffle=True)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=CFG.batch_size,\n",
    "                                                   sampler=train_sampler,\n",
    "                                                   drop_last=True,\n",
    "                                                   num_workers=CFG.num_workers)\n",
    "        \n",
    "        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset,\n",
    "                                                                        num_replicas=xm.xrt_world_size(),\n",
    "                                                                        rank=xm.get_ordinal(),\n",
    "                                                                        shuffle=False)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                                   batch_size=CFG.batch_size * 2,\n",
    "                                                   sampler=valid_sampler,\n",
    "                                                   drop_last=False,\n",
    "                                                   num_workers=CFG.num_workers)\n",
    "        \n",
    "    # ====================================================\n",
    "    # scheduler \n",
    "    # ====================================================\n",
    "    def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "    \n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    if CFG.device == 'TPU':\n",
    "        device = xm.xla_device()\n",
    "    elif CFG.device == 'GPU':\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = CustomResNet200D(CFG.model_name, pretrained=False)\n",
    "    model.load_state_dict(torch.load(CFG.student, map_location=torch.device('cpu'))['model'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    \n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    train_fc = FocalLoss(CFG.alpha, CFG.gamma)\n",
    "    valid_fc = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        if CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                avg_loss = train_fn(train_loader, model, train_fc, valid_fc, optimizer, epoch, scheduler, device)\n",
    "            elif CFG.nprocs == 8:\n",
    "                para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
    "                avg_loss = train_fn(para_train_loader.per_device_loader(device), model, train_fc, valid_fc, optimizer, epoch, scheduler, device)\n",
    "        elif CFG.device == 'GPU':\n",
    "            avg_loss = train_fn(train_loader, model, train_fc, valid_fc, optimizer, epoch, scheduler, device)\n",
    "        \n",
    "        # eval\n",
    "        if CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                avg_val_loss, preds, _ = valid_fn(valid_loader, model, valid_fc, device)\n",
    "            elif CFG.nprocs == 8:\n",
    "                para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
    "                avg_val_loss, preds, valid_labels = valid_fn(para_valid_loader.per_device_loader(device), model, valid_fc, device)\n",
    "                preds = idist.all_gather(torch.tensor(preds)).to('cpu').numpy()\n",
    "                valid_labels = idist.all_gather(torch.tensor(valid_labels)).to('cpu').numpy()\n",
    "        elif CFG.device == 'GPU':\n",
    "            avg_val_loss, preds, _ = valid_fn(valid_loader, model, valid_fc, device)\n",
    "            \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "            \n",
    "        # scoring\n",
    "        score, scores = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        if CFG.device == 'GPU':\n",
    "            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        elif CFG.device == 'TPU':\n",
    "            if CFG.nprocs == 1:\n",
    "                LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "            elif CFG.nprocs == 8:\n",
    "                xm.master_print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "                xm.master_print(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "                \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            if CFG.device == 'GPU':\n",
    "                LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                torch.save({'model': model.state_dict(), \n",
    "                            'preds': preds},\n",
    "                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "            elif CFG.device == 'TPU':\n",
    "                if CFG.nprocs == 1:\n",
    "                    LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                elif CFG.nprocs == 8:\n",
    "                    xm.master_print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "                xm.save({'model': model, \n",
    "                         'preds': preds}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "        \n",
    "        # inference用に全て保存しておく\n",
    "        if CFG.device == 'TPU':\n",
    "            xm.save({'model': model}, OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch+1}.pth')\n",
    "        elif CFG.device == 'GPU':\n",
    "            torch.save({'model': model.state_dict()}, OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch+1}.pth')\n",
    "        \n",
    "        if CFG.nprocs != 8:\n",
    "            check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "            for c in [f'pred_{c}' for c in CFG.target_cols]:\n",
    "                valid_folds[c] = np.nan\n",
    "            valid_folds[[f'pred_{c}' for c in CFG.target_cols]] = check_point['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# main\n",
    "# ====================================================\n",
    "def main():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare: 1.train  2.folds\n",
    "    \"\"\"\n",
    "\n",
    "    def get_result(result_df):\n",
    "        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n",
    "        labels = result_df[CFG.target_cols].values\n",
    "        score, scores = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n",
    "        \n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(folds, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                if CFG.nprocs != 8:\n",
    "                    LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                    get_result(_oof_df)\n",
    "                    \n",
    "        if CFG.nprocs != 8:\n",
    "            # CV result\n",
    "            LOGGER.info(f\"========== CV ==========\")\n",
    "            get_result(oof_df)\n",
    "            # save result\n",
    "            oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.90 GiB total capacity; 14.97 GiB already allocated; 39.75 MiB free; 15.11 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0617f87afd09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-32e4bead1796>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnprocs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-6c2b1f02a891>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(folds, fold)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_train_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_device_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2c06c545d765>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, train_fc, valid_fc, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4bf066e6c0db>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mpooled_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/pytorch-image-models/pytorch-image-models-master/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/pytorch-image-models/pytorch-image-models-master/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/input/pytorch-image-models/pytorch-image-models-master/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_block\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.90 GiB total capacity; 14.97 GiB already allocated; 39.75 MiB free; 15.11 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if CFG.device == 'TPU':\n",
    "        def _mp_fn(rank, flags):\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')\n",
    "            a = main()\n",
    "        FLAGS = {}\n",
    "        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n",
    "    elif CFG.device == 'GPU':\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as cpu\n",
    "if CFG.device == 'TPU':\n",
    "    for fold in range(CFG.n_fold):\n",
    "        if fold in CFG.trn_fold:\n",
    "            # best score\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score_cpu.pth')\n",
    "            # best loss\n",
    "            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n",
    "            torch.save({'model': state['model'].to('cpu').state_dict(), \n",
    "                        'preds': state['preds']}, \n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss_cpu.pth')\n",
    "            \n",
    "            for epoch in range(CFG.epochs):\n",
    "                state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_epoch{epoch+1}.pth')\n",
    "                torch.save({'model': state['model'].to('cpu').state_dict()}, \n",
    "                            OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_{epoch+1}_cpu.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
